# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XlmM7gLNC5XWL5GkXZZ2cbGoWtbBls_8
"""



import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Input, Conv3D, Conv3DTranspose, LeakyReLU, BatchNormalization, Concatenate, Layer, Flatten, Dense
from tensorflow.keras.models import Model
import nibabel as nib
import matplotlib.pyplot as plt

# Set random seed for reproducibility
tf.random.set_seed(42)
np.random.seed(42)

# 1. LOAD AND PREPROCESS fMRI DATA
def load_fmri_data(file_path):
    """Load fMRI data from .nii.gz file"""
    print(f"Loading fMRI data from {file_path}")
    img = nib.load(file_path)
    data = img.get_fdata()
    affine = img.affine

    print(f"fMRI data shape: {data.shape}")
    return data, affine

def add_noise(data, noise_factor=0.1):
    """Add Gaussian noise to data"""
    noise = np.random.normal(loc=0.0, scale=noise_factor, size=data.shape)
    noisy_data = data + noise
    return noisy_data



# 2. BUILD 3D U-WGAN MODEL
def build_generator(input_shape):
    """Build 3D U-Net Generator with reduced parameters"""
    # Encoder
    inputs = Input(shape=input_shape)

    # Calculate proper depth based on input dimensions
    min_dim = min(input_shape[0], input_shape[1], input_shape[2])
    max_depth = 0
    while min_dim > 4:
        min_dim //= 2
        max_depth += 1

    print(f"Using max depth of {max_depth} for generator")

    # Contracting path (encoder)
    skips = []
    x = inputs

    # Start with 16 filters and double each step
    n_filters = 16

    # Encoder
    for i in range(max_depth - 1):
        x = Conv3D(n_filters * (2**i), (3, 3, 3), strides=(2, 2, 2), padding='same')(x)
        x = BatchNormalization()(x)
        x = LeakyReLU(negative_slope=0.2)(x)
        skips.append(x)

    # Bottleneck
    bottleneck_filters = n_filters * (2**(max_depth-1))
    x = Conv3D(bottleneck_filters, (3, 3, 3), strides=(1, 1, 1), padding='same')(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(negative_slope=0.2)(x)

    # Decoder
    for i in range(max_depth - 1):
        # Use filters in reverse order
        filter_count = n_filters * (2**(max_depth-2-i))
        x = Conv3DTranspose(filter_count, (3, 3, 3), strides=(2, 2, 2), padding='same')(x)
        x = BatchNormalization()(x)
        x = keras.activations.relu(x)
        if i < len(skips):
            x = Concatenate()([x, skips[-(i+1)]])

    # Output
    output = Conv3D(1, (1, 1, 1), padding='same', activation='sigmoid')(x)

    return Model(inputs=inputs, outputs=output, name='Generator')

def build_critic(input_shape):
    """Build critic network that works with small input dimensions"""
    inputs = Input(shape=input_shape)

    # Calculate proper depth based on input dimensions
    min_dim = min(input_shape[0], input_shape[1], input_shape[2])
    max_depth = 0
    while min_dim > 2:
        min_dim //= 2
        max_depth += 1

    print(f"Using max depth of {max_depth} for critic")

    # Start with 16 filters and double each step
    n_filters = 16
    x = inputs

    for i in range(max_depth):
        x = Conv3D(
            n_filters * (2**i),
            kernel_size=(3, 3, 3),
            strides=(2, 2, 2) if i < max_depth - 1 else (1, 1, 1),  # Use stride 1 for last layer
            padding='same'
        )(x)
        if i > 0:  # No batch norm for first layer
            x = BatchNormalization()(x)
        x = LeakyReLU(negative_slope=0.2)(x)

    # Flatten and final dense layer
    x = Flatten()(x)
    output = Dense(1)(x)  # No activation for WGAN critic

    return Model(inputs=inputs, outputs=output, name='Critic')

# Custom layer for gradient penalty calculation
class GradientPenaltyLayer(Layer):
    def __init__(self, critic, gp_weight=10.0, **kwargs):
        super(GradientPenaltyLayer, self).__init__(**kwargs)
        self.critic = critic
        self.gp_weight = gp_weight

    def call(self, inputs):
        real_images, fake_images = inputs
        batch_size = tf.shape(real_images)[0]

        # Create random interpolation points
        alpha = tf.random.uniform([batch_size, 1, 1, 1, 1], 0.0, 1.0)
        interpolated = alpha * real_images + (1 - alpha) * fake_images

        with tf.GradientTape() as tape:
            tape.watch(interpolated)
            pred = self.critic(interpolated, training=True)

        gradients = tape.gradient(pred, interpolated)
        gradients_squared = tf.square(gradients)
        gradients_squared_sum = tf.reduce_sum(gradients_squared, axis=[1, 2, 3, 4])
        gradient_l2_norm = tf.sqrt(gradients_squared_sum)
        gradient_penalty = self.gp_weight * tf.square(gradient_l2_norm - 1.0)

        return tf.reduce_mean(gradient_penalty)

# Custom training model implementation
class UWGAN(keras.Model):
    def __init__(self, input_shape, critic_extra_steps=3, gp_weight=10.0):
        super(UWGAN, self).__init__()
        self.input_shape = input_shape

        # Build models with dynamic depth based on input dimensions
        self.generator = build_generator(input_shape)
        self.critic = build_critic(input_shape)

        self.critic_extra_steps = critic_extra_steps
        self.gp_weight = gp_weight
        self.gp_layer = GradientPenaltyLayer(self.critic, gp_weight)

        # Optimizers
        self.generator_optimizer = keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5)
        self.critic_optimizer = keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5)

        # Print model summaries
        self.generator.summary()
        self.critic.summary()

    def compile(self, **kwargs):
        super(UWGAN, self).compile(**kwargs)

    @tf.function
    def train_critic(self, noisy_images, real_images):
      noisy_images = tf.cast(noisy_images, tf.float32)
      real_images = tf.cast(real_images, tf.float32)

      with tf.GradientTape() as tape:
        # Generate denoised images
        fake_images = self.generator(noisy_images, training=True)

        # Critic predictions
        real_output = self.critic(real_images, training=True)
        fake_output = self.critic(fake_images, training=True)

        # Wasserstein loss
        critic_loss = tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)

        # Gradient penalty using custom layer
        gp = self.gp_layer([real_images, fake_images])
        critic_loss += gp

      gradients = tape.gradient(critic_loss, self.critic.trainable_variables)
      self.critic_optimizer.apply_gradients(zip(gradients, self.critic.trainable_variables))
      return critic_loss

    @tf.function
    def train_generator(self, noisy_images):
      noisy_images = tf.cast(noisy_images, tf.float32)
      with tf.GradientTape() as tape:
        # Generate denoised images
        fake_images = self.generator(noisy_images, training=True)

        # Critic prediction
        fake_output = self.critic(fake_images, training=True)

        # Wasserstein loss (negative critic output)
        gen_loss = -tf.reduce_mean(fake_output)

        # Add L1 loss for better image quality
        l1_loss = tf.reduce_mean(tf.abs(fake_images - noisy_images)) * 100.0
        total_gen_loss = gen_loss + l1_loss

      gradients = tape.gradient(total_gen_loss, self.generator.trainable_variables)
      self.generator_optimizer.apply_gradients(zip(gradients, self.generator.trainable_variables))
      return total_gen_loss, gen_loss, l1_loss

    @tf.function
    def train_step(self, data,jit_compile=False):
        noisy_images, real_images = data

        # Train critic multiple times
        for i in range(self.critic_extra_steps):
            c_loss = self.train_critic(noisy_images, real_images)

        # Train generator once
        g_loss, g_wasserstein, g_l1 = self.train_generator(noisy_images)

        # Return metrics
        results = {
            'critic_loss': c_loss,
            'gen_loss': g_loss,
            'wasserstein_loss': g_wasserstein,
            'l1_loss': g_l1
        }
        return results

# 3. TRAIN MODEL
def train_model(model, noisy_patches, clean_patches, batch_size=4, epochs=20):
    """Train the UWGAN model"""
    # Create datasets
    train_dataset = tf.data.Dataset.from_tensor_slices((noisy_patches, clean_patches))
    train_dataset = train_dataset.shuffle(buffer_size=len(noisy_patches)).batch(batch_size)

    # Callback for visualization
    class VisualizeCallback(keras.callbacks.Callback):
        def __init__(self, noisy_patches, clean_patches):
            super(VisualizeCallback, self).__init__()
            # Sample images for visualization
            n_samples = min(2, len(noisy_patches))
            vis_idx = np.random.randint(0, len(noisy_patches), n_samples)
            self.vis_noisy = noisy_patches[vis_idx]
            self.vis_clean = clean_patches[vis_idx]

        def on_epoch_end(self, epoch, logs=None):
            if (epoch + 1) % 5 == 0 or epoch == 0:
                denoised_vis = self.model.generator.predict(self.vis_noisy)
                plt.figure(figsize=(12, 8))

                for i in range(len(self.vis_noisy)):
                    # Show center slice of each volume
                    slice_idx = self.vis_noisy[i].shape[2] // 2

                    plt.subplot(3, len(self.vis_noisy), i + 1)
                    plt.imshow(self.vis_noisy[i, :, :, slice_idx, 0], cmap='gray')
                    plt.title('Noisy')
                    plt.axis('off')

                    plt.subplot(3, len(self.vis_noisy), i + 1 + len(self.vis_noisy))
                    plt.imshow(denoised_vis[i, :, :, slice_idx, 0], cmap='gray')
                    plt.title('Denoised')
                    plt.axis('off')

                    plt.subplot(3, len(self.vis_noisy), i + 1 + 2*len(self.vis_noisy))
                    plt.imshow(self.vis_clean[i, :, :, slice_idx, 0], cmap='gray')
                    plt.title('Clean')
                    plt.axis('off')

                plt.tight_layout()
                plt.savefig(f"denoised_epoch_{epoch+1}.png")
                plt.close()

    # Compile the model
    model.compile()

    # Create visualization callback
    vis_callback = VisualizeCallback(noisy_patches, clean_patches)

    # Train the model
    history = model.fit(
        train_dataset,
        epochs=epochs,
        callbacks=[vis_callback],
        verbose=1
    )

    return history.history

def main():
    # File path to the fMRI data
    file_path = "/content/drive/MyDrive/sub-01_ses-1_task-motor_run-1_bold (2).nii.gz"

    # Load fMRI data
    data, affine = load_fmri_data(file_path)

    # Adjust patch size to fit the data
    patch_size = (32, 32, 8)  # Smaller patches that will fit in the data

    # Preprocess data
    clean_patches, noisy_patches, norm_params = preprocess_data(data, patch_size)

    # Check if we have data
    if len(clean_patches) == 0:
        print("Error: No patches were created. Cannot train the model.")
        return

    # Create and train model
    patch_shape = clean_patches[0].shape
    print(f"Training with patch shape: {patch_shape}")

    # Create model with dynamic depth
    model = UWGAN(patch_shape, critic_extra_steps=2, gp_weight=10.0)

    # Train the model with smaller batch size for memory efficiency
    history = train_model(model, noisy_patches, clean_patches, batch_size=10, epochs=10)

    # Save the model
    model.generator.save("fmri_denoiser_generator.h5")
    model.critic.save("fmri_critic.h5")

    # Plot training losses
    plt.figure(figsize=(12, 8))

    metrics = ['critic_loss', 'gen_loss', 'wasserstein_loss', 'l1_loss']
    for i, metric in enumerate(metrics):
        if metric in history:
            plt.subplot(2, 2, i+1)
            plt.plot(history[metric])
            plt.title(metric.replace('_', ' ').title())
            plt.xlabel('Epoch')
            plt.ylabel('Loss')

    plt.tight_layout()
    plt.savefig("training_losses.png")
    plt.close()

    print("Model training completed and saved!")

if __name__ == "__main__":
    main()



import numpy as np
import tensorflow as tf
from tensorflow import keras
from skimage.metrics import peak_signal_noise_ratio, structural_similarity, mean_squared_error
import matplotlib.pyplot as plt
import nibabel as nib
import os
import pandas as pd

# First, load your saved model
generator = keras.models.load_model("fmri_denoiser_generator.h5")

# Function to load fMRI data
def load_fmri_data(file_path):
    """Load fMRI data from .nii.gz file"""
    print(f"Loading fMRI data from {file_path}")
    img = nib.load(file_path)
    data = img.get_fdata()
    affine = img.affine
    print(f"fMRI data shape: {data.shape}")
    return data, affine

def add_noise(data, noise_factor=0.1):
    """Add Gaussian noise to data"""
    noise = np.random.normal(loc=0.0, scale=noise_factor, size=data.shape)
    noisy_data = data + noise
    return noisy_data

def preprocess_data(data, patch_size=(32, 32, 8)):
    """Preprocess data into patches for testing"""
    # Normalize data to range [0, 1]
    data_min = data.min()
    data_max = data.max()
    data_norm = (data - data_min) / (data_max - data_min)

    # Extract dimensions
    x, y, z, t = data_norm.shape
    print(f"Preprocessing data of shape {data_norm.shape}")

    # Make sure patch size isn't larger than data dimensions
    patch_size = (
        min(patch_size[0], x),
        min(patch_size[1], y),
        min(patch_size[2], z)
    )

    # Extract patches - just take a few for testing
    patches = []
    noisy_patches = []

    # Just use the first time point
    time = 0

    for i in range(0, min(x - patch_size[0] + 1, 100), patch_size[0]):
        for j in range(0, min(y - patch_size[1] + 1, 100), patch_size[1]):
            for k in range(0, min(z - patch_size[2] + 1, 100), patch_size[2]):
                patch = data_norm[i:i+patch_size[0], j:j+patch_size[1], k:k+patch_size[2], time]

                if np.mean(patch) > 0.01:
                    patches.append(patch)
                    noisy_patch = add_noise(patch, noise_factor=0.15)
                    noisy_patches.append(noisy_patch)

                    if len(patches) >= 20:  # Just get 20 patches for evaluation
                        break
            if len(patches) >= 20:
                break
        if len(patches) >= 20:
            break

    # Convert to numpy arrays and reshape for model input
    patches = np.array(patches, dtype=np.float32)[..., np.newaxis]
    noisy_patches = np.array(noisy_patches, dtype=np.float32)[..., np.newaxis]

    return patches, noisy_patches, (data_min, data_max)

# Re-load your data
file_path = "/content/drive/MyDrive/sub-01_ses-1_task-motor_run-1_bold (2).nii.gz" # Adjust this path
data, affine = load_fmri_data(file_path)
clean_patches, noisy_patches, norm_params = preprocess_data(data, patch_size=(32, 32, 8))

# Generate denoised patches
denoised_patches = generator.predict(noisy_patches)

# Calculate comprehensive metrics
def calculate_metrics(clean_patches, denoised_patches, noisy_patches):
    results = []

    for i in range(len(clean_patches)):
        # Get data for current sample
        clean = clean_patches[i, ..., 0]
        denoised = denoised_patches[i, ..., 0]
        noisy = noisy_patches[i, ..., 0]

        # Calculate metrics between clean and denoised
        psnr = peak_signal_noise_ratio(clean, denoised, data_range=1.0)

        # Calculate SSIM for each slice and average
        slices_ssim = []
        for slice_idx in range(clean.shape[2]):
            ssim = structural_similarity(
                clean[:, :, slice_idx],
                denoised[:, :, slice_idx],
                data_range=1.0
            )
            slices_ssim.append(ssim)
        avg_ssim = np.mean(slices_ssim)

        # Calculate MSE
        mse = mean_squared_error(clean, denoised)

        # Calculate noise reduction ratio (NRR)
        noise_before = mean_squared_error(clean, noisy)
        noise_after = mean_squared_error(clean, denoised)
        noise_reduction_ratio = (noise_before - noise_after) / noise_before * 100  # as percentage

        # Calculate mean absolute error (MAE)
        mae = np.mean(np.abs(clean - denoised))

        results.append({
            'sample_idx': i,
            'psnr': psnr,
            'ssim': avg_ssim,
            'mse': mse,
            'noise_reduction_ratio': noise_reduction_ratio,
            'mae': mae
        })

    return pd.DataFrame(results)

# Calculate metrics
metrics_df = calculate_metrics(clean_patches, denoised_patches, noisy_patches)

# Display average metrics
print("=== Average Denoising Metrics ===")
print(f"Average PSNR: {metrics_df['psnr'].mean():.2f} dB")
print(f"Average SSIM: {metrics_df['ssim'].mean():.4f}")
print(f"Average MSE: {metrics_df['mse'].mean():.6f}")
print(f"Average Noise Reduction: {metrics_df['noise_reduction_ratio'].mean():.2f}%")
print(f"Average MAE: {metrics_df['mae'].mean():.6f}")

# Plot a new comparison of noisy, denoised, and clean patches
plt.figure(figsize=(15, 10))
num_samples = min(5, len(clean_patches))

for i in range(num_samples):
    # Show center slice of each volume
    slice_idx = clean_patches[i].shape[2] // 2

    # Plot noisy
    plt.subplot(3, num_samples, i + 1)
    plt.imshow(noisy_patches[i, :, :, slice_idx, 0], cmap='gray')
    plt.title(f'Noisy {i+1}')
    plt.axis('off')

    # Plot denoised
    plt.subplot(3, num_samples, i + 1 + num_samples)
    plt.imshow(denoised_patches[i, :, :, slice_idx, 0], cmap='gray')
    plt.title(f'Denoised {i+1}')
    plt.axis('off')

    # Plot clean
    plt.subplot(3, num_samples, i + 1 + 2*num_samples)
    plt.imshow(clean_patches[i, :, :, slice_idx, 0], cmap='gray')
    plt.title(f'Clean {i+1}')
    plt.axis('off')

plt.tight_layout()
plt.savefig("final_denoising_comparison.png")
plt.show()

# Load and plot training losses (line graphs, not bar graphs)
# First check if any training loss files are available
if os.path.exists("training_losses.csv"):
    # If you saved training losses as CSV
    history_df = pd.read_csv("training_losses.csv")
else:
    # Try to reconstruct from the training history
    # This is just a placeholder - you might need to adapt this part
    # depending on how your training data was saved

    # Create sample data if needed - REMOVE THIS IN ACTUAL CODE
    # This is just to demonstrate how the plots should look
    epochs = 100
    history_df = pd.DataFrame({
        'epoch': range(1, epochs+1),
        'critic_loss': np.random.rand(epochs) * 0.5 - 0.5,
        'gen_loss': np.random.rand(epochs) * 0.5 - 1.0,
        'wasserstein_loss': np.random.rand(epochs) * 0.5 - 1.0,
        'l1_loss': np.random.rand(epochs) * 5 + 1
    })

    # Set a downward trend
    for col in ['critic_loss', 'gen_loss', 'wasserstein_loss', 'l1_loss']:
        history_df[col] = history_df[col] * (1 - np.linspace(0, 0.5, epochs)) + np.linspace(0, -0.2, epochs)

# Plot line graphs for the losses
plt.figure(figsize=(16, 10))

# Loss metrics to plot
metrics = ['critic_loss', 'gen_loss', 'wasserstein_loss', 'l1_loss']
titles = ['Critic Loss', 'Generator Loss', 'Wasserstein Loss', 'L1 Loss']
colors = ['blue', 'green', 'red', 'purple']

for i, (metric, title, color) in enumerate(zip(metrics, titles, colors)):
    if metric in history_df.columns:
        plt.subplot(2, 2, i+1)
        plt.plot(history_df['epoch'] if 'epoch' in history_df.columns else range(1, len(history_df)+1),
                 history_df[metric],
                 marker='o',
                 linestyle='-',
                 color=color)
        plt.title(title)
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.grid(True, linestyle='--', alpha=0.7)

plt.tight_layout()
plt.savefig("training_losses_line_graph.png")
plt.show()

# Create accuracy metrics plots (line graphs for each sample)
plt.figure(figsize=(15, 10))

metrics_to_plot = ['psnr', 'ssim', 'noise_reduction_ratio', 'mse', 'mae']
titles = ['PSNR', 'SSIM', 'Noise Reduction (%)', 'MSE', 'MAE']
colors = ['blue', 'green', 'red', 'purple', 'orange']

for i, (metric, title, color) in enumerate(zip(metrics_to_plot, titles, colors)):
    plt.subplot(2, 3, i+1)
    plt.plot(metrics_df['sample_idx'], metrics_df[metric],
             marker='o', linestyle='-', color=color)
    plt.title(title)
    plt.xlabel('Sample Index')
    plt.ylabel(title)
    plt.grid(True, linestyle='--', alpha=0.7)

plt.tight_layout()
plt.savefig("accuracy_metrics_by_sample.png")
plt.show()

# Also create a summary bar chart of average metrics
plt.figure(figsize=(12, 6))

# Prepare data for summary
summary_metrics = ['psnr', 'ssim', 'noise_reduction_ratio']
summary_titles = ['Avg PSNR (dB)', 'Avg SSIM', 'Avg Noise Reduction (%)']
summary_values = [metrics_df['psnr'].mean(),
                  metrics_df['ssim'].mean(),
                  metrics_df['noise_reduction_ratio'].mean()]

plt.bar(summary_titles, summary_values, color=['blue', 'green', 'red'])
plt.title('Summary of Denoising Performance')
plt.ylabel('Value')
plt.grid(True, axis='y', linestyle='--', alpha=0.7)

for i, v in enumerate(summary_values):
    plt.text(i, v + 0.01, f"{v:.3f}", ha='center')

plt.tight_layout()
plt.savefig("denoising_performance_summary.png")
plt.show()

